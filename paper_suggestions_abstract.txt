This research presents a deep learning neural network that utilizes LSTM and Dense layers to perform a limited symbolic propositional reasoning task. The study introduces agents capable of answering questions if the answer is known, recognizing a lack of knowledge and asking for help, and responding to requests for help with a knowledge state dump. The agents are trained to reason on sentences involving syllogisms and logical operators. The network was found to yield an error rate of slightly less than 1% on the validation data set. This work serves as a starting point for future research, including expanding the range of solvable problems, improving the selectivity of knowledge dumping, and transitioning from LSTM-based seq2seq architecture to Transformer based architecture.