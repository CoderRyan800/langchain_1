This research presents a deep learning neural network that utilizes LSTM and Dense layers to perform basic symbolic propositional reasoning tasks. The network is designed to train agents that can answer questions based on their knowledge, recognize when they lack the necessary information, and request assistance. These agents can also respond to help requests by providing a dump of their knowledge state. The study demonstrates the concept of learning a knowledge state in a simple case. The network has been tested and found to yield an error rate of less than 1% on the validation data set. Future work may involve expanding the range of problems the network can solve, improving the selectivity of knowledge dumps, and transitioning from the current LSTM-based seq2seq architecture to a Transformer-based architecture.